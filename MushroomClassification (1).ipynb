{"cells":[{"metadata":{"_uuid":"995830f4-bd03-4b1b-85ff-6375f86885d6","_cell_guid":"c74d4053-96c6-4a19-89e0-61f39c78e78f","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"4148b932-4486-45cc-a1ee-31a766cc6799","_cell_guid":"7fe3decf-b4ea-4c3d-899c-17fc42ac857b","trusted":true},"cell_type":"code","source":"import torch\ntorch.cuda.is_available()\nimport torchvision.models as models\nVGG16 = models.vgg16(pretrained=True)\nVGG16","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"b9058eed-5fa8-480d-94d4-0df755a1d030","_cell_guid":"715f57fd-1bad-47c8-a2e2-652330af4589","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom glob import glob\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch\n\nmushrooms_files = np.array(glob('../input/mushrooms-classification-common-genuss-images/Mushrooms/*/*'))\n#dog_files = np.array(glob(\"/Users/hataechan/desktop/cnncifar10/muchroomclassification/mushrooms/*/*\"))\n\nimport cv2                \nimport matplotlib.pyplot as plt                        \n%matplotlib inline\n\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n\nimport os\nfrom torchvision import datasets\n\n### TODO: Write data loaders for training, validation, and test sets\n## Specify appropriate transforms, and batch_sizes\n\nbatch_size = 32\n\ndata_transforms = {'train': transforms.Compose([\n                                     #transforms.RandomResizedCrop(224),\n                                     #transforms.RandomHorizontalFlip(),\n                                     transforms.Resize(256),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(\n                                                    [0.485, 0.456, 0.406],\n                                                    [0.229, 0.224, 0.225])]),\n                   'valid': transforms.Compose([\n                                     transforms.Resize(256),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(\n                                                    [0.485, 0.456, 0.406],\n                                                    [0.229, 0.224, 0.225])]),\n                   'test': transforms.Compose([\n                                     transforms.Resize(256),\n                                     transforms.ToTensor(), \n                                     transforms.Normalize(\n                                                    [0.485, 0.456, 0.406],\n                                                    [0.229, 0.224, 0.225])]),\n}\ndata_dir = '../input/mushrooms-classification-common-genuss-images/Mushrooms/'\nimage_datasets = datasets.ImageFolder(data_dir, data_transforms['train'])\ntrain_size = int(0.8 * len(image_datasets))\ntest_size = len(image_datasets) - train_size\nvalid_size = int(train_size * 0.2)\ntrain_size = int(train_size - valid_size)\nprint(train_size, valid_size, test_size)\n\ntrain_set, valid_set, test_set = torch.utils.data.random_split(image_datasets, [train_size, valid_size, test_size])\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n\n'''\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'valid', 'test']}\nloaders_scratch = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n                                             shuffle=True)\n              for x in ['train', 'valid', 'test']}\n'''\nimport torch\nimport torchvision.models as models\n\nVGG16 = models.vgg16(pretrained=True)\n\nuse_cuda = torch.cuda.is_available()\n\nfor param in VGG16.parameters():\n    param.requires_grad = False\n    \nif use_cuda:\n    VGG16.cuda()\n    \nnumber_of_classes = len(image_datasets.classes)\nclassifier = nn.Sequential(nn.Linear(25088, 8192).cuda(),\n                           nn.ReLU(),\n                           nn.Dropout(0.5),\n                           nn.Linear(8192, 1024).cuda(),\n                           nn.ReLU(),\n                           nn.Dropout(0.5),\n                           nn.Linear(1024, number_of_classes).cuda())\nVGG16.classifier = classifier\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(VGG16.classifier.parameters(), lr=0.001)\n\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\ndef train(n_epochs, train_loader, valid_loader, model, optimizer, criterion, use_cuda, save_path):\n\n    valid_loss_min = np.Inf\n    \n    print(f\"Batch Size: {train_loader.batch_size}\\n\")\n    \n    for epoch in range(1, n_epochs+1):\n        train_loss = 0.0\n        valid_loss = 0.0\n        \n        # train the model\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n            \n            if (batch_idx + 1) % 5 == 0:\n                print(f'Epoch:{epoch}/{n_epochs} \\tBatch:{batch_idx + 1}')\n                print(f'Train Loss: {train_loss}\\n')\n\n        # validate the model\n        model.eval()\n        for batch_idx, (data, target) in enumerate(valid_loader):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            with torch.no_grad():\n                output = model(data)\n            loss = criterion(output, target)\n            valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n           \n        # print training/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            valid_loss\n            ))\n        \n        # save the model if validation loss has decreased\n        if valid_loss < valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model...'.format(valid_loss_min, valid_loss))\n            torch.save(model.state_dict(), save_path)\n            valid_loss_min = valid_loss\n            \n    # return trained model\n    return model\n\nVGG16 = train(3, train_loader, valid_loader, VGG16, optimizer,\n                       criterion, use_cuda, 'model_mush.pt')\n\n# load the model that got the best validation accuracy\nVGG16.load_state_dict(torch.load('model_mush.pt'))\n\ndef test(test_loader, model, criterion, use_cuda):\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n    \n    model.eval()\n    for batch_idx, (data,target) in enumerate(test_loader):\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        with torch.no_grad():\n            model.requires_grad = False\n\n        output = model(data)\n        loss = criterion(output, target)\n        \n        test_loss += test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n        \n        output = F.softmax(output, dim=1)\n        pred = output.data.max(1, keepdim=True)[1]\n        \n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n        \n        print('Test Loss: {:.6f}\\n'.format(test_loss))\n        print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))\n\nclass_name = [item[0:] for item in image_datasets.classes]\nVGG16.load_state_dict(torch.load('model_mush.pt'))\n\ndef predict_breed(img_path):\n    # load the image and return the predicted breed\n    img = Image.open(img_path)\n\n    # Define transformations of image\n    transform = transforms.Compose([transforms.Resize(256),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.485, 0.456, 0.406],\n                                                          [0.229, 0.224, 0.225])])\n    # Preprocess image to 4D Tensor (.unsqueeze(0) adds a dimension)\n    img_tensor = transform(img).unsqueeze(0)\n\n    # Move tensor to GPU if available\n    if use_cuda:\n        img_tensor = img_tensor.cuda()\n        \n    ## Inference\n    # Turn on evaluation mode\n    VGG16.eval()\n    \n    # Get predicted category for image\n    with torch.no_grad():\n        output = VGG16(img_tensor)\n\n    prediction = torch.argmax(output).item() \n    print(output, torch.argmax(output).item())\n    # Turn off evaluation mode\n    VGG16.train()\n    \n    # Use prediction to get dog breed\n    breed = class_names[prediction]\n    \n    return breed\n\ntest(test_loader, VGG16, criterion, use_cuda)\n\ndef run_app(img_path):\n        plt.imshow(Image.open(img_path))\n        plt.show()\n        print(f'This is a picture of a ... {predict_breed(img_path)}')\n        print('\\n-----------------------------------\\n')\n\nfor file in np.hstack(mushrooms_files[:3]):\n    run_app(file)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c40ff473-baba-43bc-b787-ac135bd0efa4","_cell_guid":"1d276752-9165-4b2a-87b1-2eb3d748a69d","trusted":true},"cell_type":"code","source":"def predict_breed(img_path):\n    # load the image and return the predicted breed\n    img = Image.open(img_path)\n\n    # Define transformations of image\n    transform = transforms.Compose([transforms.Resize(256),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.485, 0.456, 0.406],\n                                                          [0.229, 0.224, 0.225])])\n    # Preprocess image to 4D Tensor (.unsqueeze(0) adds a dimension)\n    img_tensor = transform(img).unsqueeze(0)\n\n    # Move tensor to GPU if available\n    if use_cuda:\n        img_tensor = img_tensor.cuda()\n        \n    ## Inference\n    # Turn on evaluation mode\n    VGG16.eval()\n    \n    # Get predicted category for image\n    with torch.no_grad():\n        output = VGG16(img_tensor)\n\n    prediction = torch.argmax(output).item() \n    # Turn off evaluation mode\n    VGG16.train()\n    \n    # Use prediction to get dog breed\n    breed = class_names[prediction]\n    \n    return breed\n\nfor file in np.hstack(mushrooms_files[:3]):\n    plt.show(Image.open(file))\n    plt.show()\n    print(\"breed is \",predict_breed(file))\n\ndef train(n_epochs, train_loader, valid_loader, model, optimizer, criterion, use_cuda, save_path):\n    \n    valid_loss_min = np.Inf\n    \n    print(\"Training...\")\n    \n    for epoch in (1, n_epochs+1):\n        \n        train_loss = 0.0\n        valid_loss = 0.0\n        \n        model.train()\n        for batch_idx, (data,target) in enumerate(train_loader):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            \n            output = model(data)\n            loss = criterion(output, target)\n            print(\"data: \",data.shape,\"\\n\",\"target: \",target,\"\\n\",\"output: \", output,\"\\n\",\"loss: \", loss)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += (1 / (batch_idx + 1)) * (loss.data - train_loss)\n            print(\"epoch: {epoch}/{n_epochs}\\t batch: {batch_idx + 1}\")\n            print(\"training loss: {train_loss}\")\n            if batch_idx == 0:\n                break\n            \n        model.eval()\n        for batch_idx, (data, target) in enumerate(valid_loader):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()    \n            with torch.no_grad():\n                output = model(data)\n                \n            loss = criterion(output, target)\n            \n            valid_loss += (1 / (batch_idx + 1)) * (loss.data - valid_loss) \n            if batch_idx == 0:\n                break\n            \n        if valid_loss < valid_loss_min:\n            print(\"Validation loss decreased ({:.6f} --> {:.6f}). Saving model...\".format(valid_loss_min, valid_loss))\n            torch.save(model.state_dict(), save_path)\n            valid_loss_min = valid_loss\n\n        return model\nVGG16 = train(7, train_loader, valid_loader, VGG16, optimizer, criterion, use_cuda, 'model_mush.pt')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"5b9d7bc3-3e2d-47b1-9ca2-8a63d357416e","_cell_guid":"f8f296f2-246e-44f7-b100-4d1a2fb41d93","trusted":true},"cell_type":"code","source":"VGG16.load_state_dict(torch.load('model_mush.pt'))\ndef test(test_loader, model, criterion, use_cuda):\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n    \n    model.eval()\n    for batch_idx, (data,target) in enumerate(test_loader):\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        with torch.no_grad():\n            model.requires_grad = False\n\n        output = model(data)\n        loss = criterion(output, target)\n        \n        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n        \n        output = F.softmax(output, dim=1)\n        pred = output.data.max(1, keepdim=True)[1]\n        \n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n        \n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))\n        \ntest(test_loader, VGG16, criterion, use_cuda)","execution_count":124,"outputs":[{"output_type":"stream","text":"Test Loss: 0.943538\n\n\nTest Accuracy: 68% (920/1343)\n","name":"stdout"}]},{"metadata":{"_uuid":"0c825350-1e12-4111-a6d7-fba3bf308e7f","_cell_guid":"6813f878-638c-4032-a692-87641249293b","trusted":true},"cell_type":"code","source":"def run_app(img_path):\n        plt.imshow(Image.open(img_path))\n        plt.show()\n        print(f'This is a picture of a ... {predict_breed(img_path)}')\n        print('\\n-----------------------------------\\n')\n        \nfor file in np.hstack(mushrooms_files[48:51]):\n    run_app(file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}