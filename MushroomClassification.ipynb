{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\ntorch.cuda.is_available()\nimport torchvision.models as models\nVGG16 = models.vgg16(pretrained=True)\nVGG16","execution_count":117,"outputs":[{"output_type":"execute_result","execution_count":117,"data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom glob import glob\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch\n\nmushrooms_files = np.array(glob('../input/mushrooms-classification-common-genuss-images/Mushrooms/*/*'))\n#dog_files = np.array(glob(\"/Users/hataechan/desktop/cnncifar10/muchroomclassification/mushrooms/*/*\"))\n\nimport cv2                \nimport matplotlib.pyplot as plt                        \n%matplotlib inline\n\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n\nimport os\nfrom torchvision import datasets\n\n### TODO: Write data loaders for training, validation, and test sets\n## Specify appropriate transforms, and batch_sizes\n\nbatch_size = 32\n\ndata_transforms = {'train': transforms.Compose([\n                                     #transforms.RandomResizedCrop(224),\n                                     #transforms.RandomHorizontalFlip(),\n                                     transforms.Resize(256),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(\n                                                    [0.485, 0.456, 0.406],\n                                                    [0.229, 0.224, 0.225])]),\n                   'valid': transforms.Compose([\n                                     transforms.Resize(256),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(\n                                                    [0.485, 0.456, 0.406],\n                                                    [0.229, 0.224, 0.225])]),\n                   'test': transforms.Compose([\n                                     transforms.Resize(256),\n                                     transforms.ToTensor(), \n                                     transforms.Normalize(\n                                                    [0.485, 0.456, 0.406],\n                                                    [0.229, 0.224, 0.225])]),\n}\ndata_dir = '../input/mushrooms-classification-common-genuss-images/Mushrooms/'\nimage_datasets = datasets.ImageFolder(data_dir, data_transforms['train'])\ntrain_size = int(0.8 * len(image_datasets))\ntest_size = len(image_datasets) - train_size\nvalid_size = int(train_size * 0.2)\ntrain_size = int(train_size - valid_size)\nprint(train_size, valid_size, test_size)\n\ntrain_set, valid_set, test_set = torch.utils.data.random_split(image_datasets, [train_size, valid_size, test_size])\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n\n'''\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'valid', 'test']}\nloaders_scratch = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n                                             shuffle=True)\n              for x in ['train', 'valid', 'test']}\n'''\nimport torch\nimport torchvision.models as models\n\nVGG16 = models.vgg16(pretrained=True)\n\nuse_cuda = torch.cuda.is_available()\n\nfor param in VGG16.parameters():\n    param.requires_grad = False\n    \nif use_cuda:\n    VGG16.cuda()\n    \nnumber_of_classes = len(image_datasets.classes)\nclassifier = nn.Sequential(nn.Linear(25088, 8192).cuda(),\n                           nn.ReLU(),\n                           nn.Dropout(0.5),\n                           nn.Linear(8192, 1024).cuda(),\n                           nn.ReLU(),\n                           nn.Dropout(0.5),\n                           nn.Linear(1024, number_of_classes).cuda())\nVGG16.classifier = classifier\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(VGG16.classifier.parameters(), lr=0.001)\n\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\ndef train(n_epochs, train_loader, valid_loader, model, optimizer, criterion, use_cuda, save_path):\n\n    valid_loss_min = np.Inf\n    \n    print(f\"Batch Size: {train_loader.batch_size}\\n\")\n    \n    for epoch in range(1, n_epochs+1):\n        train_loss = 0.0\n        valid_loss = 0.0\n        \n        # train the model\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n            \n            if (batch_idx + 1) % 5 == 0:\n                print(f'Epoch:{epoch}/{n_epochs} \\tBatch:{batch_idx + 1}')\n                print(f'Train Loss: {train_loss}\\n')\n\n        # validate the model\n        model.eval()\n        for batch_idx, (data, target) in enumerate(valid_loader):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            with torch.no_grad():\n                output = model(data)\n            loss = criterion(output, target)\n            valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n           \n        # print training/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            valid_loss\n            ))\n        \n        # save the model if validation loss has decreased\n        if valid_loss < valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model...'.format(valid_loss_min, valid_loss))\n            torch.save(model.state_dict(), save_path)\n            valid_loss_min = valid_loss\n            \n    # return trained model\n    return model\n\nVGG16 = train(3, train_loader, valid_loader, VGG16, optimizer,\n                       criterion, use_cuda, 'model_mush.pt')\n\n# load the model that got the best validation accuracy\nVGG16.load_state_dict(torch.load('model_mush.pt'))\n\ndef test(test_loader, model, criterion, use_cuda):\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n    \n    model.eval()\n    for batch_idx, (data,target) in enumerate(test_loader):\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        with torch.no_grad():\n            model.requires_grad = False\n\n        output = model(data)\n        loss = criterion(output, target)\n        \n        test_loss += test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n        \n        output = F.softmax(output, dim=1)\n        pred = output.data.max(1, keepdim=True)[1]\n        \n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n        \n        print('Test Loss: {:.6f}\\n'.format(test_loss))\n        print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))\n\nclass_name = [item[0:] for item in image_datasets.classes]\nVGG16.load_state_dict(torch.load('model_mush.pt'))\n\ndef predict_breed(img_path):\n    # load the image and return the predicted breed\n    img = Image.open(img_path)\n\n    # Define transformations of image\n    transform = transforms.Compose([transforms.Resize(256),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.485, 0.456, 0.406],\n                                                          [0.229, 0.224, 0.225])])\n    # Preprocess image to 4D Tensor (.unsqueeze(0) adds a dimension)\n    img_tensor = transform(img).unsqueeze(0)\n\n    # Move tensor to GPU if available\n    if use_cuda:\n        img_tensor = img_tensor.cuda()\n        \n    ## Inference\n    # Turn on evaluation mode\n    VGG16.eval()\n    \n    # Get predicted category for image\n    with torch.no_grad():\n        output = VGG16(img_tensor)\n\n    prediction = torch.argmax(output).item() \n    print(output, torch.argmax(output).item())\n    # Turn off evaluation mode\n    VGG16.train()\n    \n    # Use prediction to get dog breed\n    breed = class_names[prediction]\n    \n    return breed\n\ntest(test_loader, VGG16, criterion, use_cuda)\n\ndef run_app(img_path):\n        plt.imshow(Image.open(img_path))\n        plt.show()\n        print(f'This is a picture of a ... {predict_breed(img_path)}')\n        print('\\n-----------------------------------\\n')\n\nfor file in np.hstack(mushrooms_files[:3]):\n    run_app(file)","execution_count":null,"outputs":[{"output_type":"stream","text":"4297 1074 1343\nBatch Size: 32\n\nEpoch:1/3 \tBatch:5\nTrain Loss: 19.10934066772461\n\nEpoch:1/3 \tBatch:10\nTrain Loss: 11.657085418701172\n\nEpoch:1/3 \tBatch:15\nTrain Loss: 8.419585227966309\n\nEpoch:1/3 \tBatch:20\nTrain Loss: 6.773863315582275\n\nEpoch:1/3 \tBatch:25\nTrain Loss: 5.805679798126221\n\nEpoch:1/3 \tBatch:30\nTrain Loss: 5.144862174987793\n\nEpoch:1/3 \tBatch:35\nTrain Loss: 4.640798568725586\n\nEpoch:1/3 \tBatch:40\nTrain Loss: 4.24794340133667\n\nEpoch:1/3 \tBatch:45\nTrain Loss: 3.958702564239502\n\nEpoch:1/3 \tBatch:50\nTrain Loss: 3.726158618927002\n\nEpoch:1/3 \tBatch:55\nTrain Loss: 3.530876636505127\n\nEpoch:1/3 \tBatch:60\nTrain Loss: 3.3618743419647217\n\nEpoch:1/3 \tBatch:65\nTrain Loss: 3.2036261558532715\n\nEpoch:1/3 \tBatch:70\nTrain Loss: 3.0728938579559326\n\nEpoch:1/3 \tBatch:75\nTrain Loss: 2.9550235271453857\n\nEpoch:1/3 \tBatch:80\nTrain Loss: 2.8546366691589355\n\nEpoch:1/3 \tBatch:85\nTrain Loss: 2.7715649604797363\n\nEpoch:1/3 \tBatch:90\nTrain Loss: 2.689548969268799\n\nEpoch:1/3 \tBatch:95\nTrain Loss: 2.613722324371338\n\nEpoch:1/3 \tBatch:100\nTrain Loss: 2.5436673164367676\n\nEpoch:1/3 \tBatch:105\nTrain Loss: 2.4924404621124268\n\nEpoch:1/3 \tBatch:110\nTrain Loss: 2.435393810272217\n\nEpoch:1/3 \tBatch:115\nTrain Loss: 2.3896312713623047\n\nEpoch:1/3 \tBatch:120\nTrain Loss: 2.3408517837524414\n\nEpoch:1/3 \tBatch:125\nTrain Loss: 2.2912909984588623\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_breed(img_path):\n    # load the image and return the predicted breed\n    img = Image.open(img_path)\n\n    # Define transformations of image\n    transform = transforms.Compose([transforms.Resize(256),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.485, 0.456, 0.406],\n                                                          [0.229, 0.224, 0.225])])\n    # Preprocess image to 4D Tensor (.unsqueeze(0) adds a dimension)\n    img_tensor = transform(img).unsqueeze(0)\n\n    # Move tensor to GPU if available\n    if use_cuda:\n        img_tensor = img_tensor.cuda()\n        \n    ## Inference\n    # Turn on evaluation mode\n    VGG16.eval()\n    \n    # Get predicted category for image\n    with torch.no_grad():\n        output = VGG16(img_tensor)\n\n    prediction = torch.argmax(output).item() \n    # Turn off evaluation mode\n    VGG16.train()\n    \n    # Use prediction to get dog breed\n    breed = class_names[prediction]\n    \n    return breed\n\nfor file in np.hstack(mushrooms_files[:3]):\n    plt.show(Image.open(file))\n    plt.show()\n    print(\"breed is \",predict_breed(file))\n\ndef train(n_epochs, train_loader, valid_loader, model, optimizer, criterion, use_cuda, save_path):\n    \n    valid_loss_min = np.Inf\n    \n    print(\"Training...\")\n    \n    for epoch in (1, n_epochs+1):\n        \n        train_loss = 0.0\n        valid_loss = 0.0\n        \n        model.train()\n        for batch_idx, (data,target) in enumerate(train_loader):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            \n            output = model(data)\n            loss = criterion(output, target)\n            print(\"data: \",data.shape,\"\\n\",\"target: \",target,\"\\n\",\"output: \", output,\"\\n\",\"loss: \", loss)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += (1 / (batch_idx + 1)) * (loss.data - train_loss)\n            print(\"epoch: {epoch}/{n_epochs}\\t batch: {batch_idx + 1}\")\n            print(\"training loss: {train_loss}\")\n            if batch_idx == 0:\n                break\n            \n        model.eval()\n        for batch_idx, (data, target) in enumerate(valid_loader):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()    \n            with torch.no_grad():\n                output = model(data)\n                \n            loss = criterion(output, target)\n            \n            valid_loss += (1 / (batch_idx + 1)) * (loss.data - valid_loss) \n            if batch_idx == 0:\n                break\n            \n        if valid_loss < valid_loss_min:\n            print(\"Validation loss decreased ({:.6f} --> {:.6f}). Saving model...\".format(valid_loss_min, valid_loss))\n            torch.save(model.state_dict(), save_path)\n            valid_loss_min = valid_loss\n\n        return model\nVGG16 = train(7, train_loader, valid_loader, VGG16, optimizer, criterion, use_cuda, 'model_mush.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VGG16.load_state_dict(torch.load('model_mush.pt'))\ndef test(test_loader, model, criterion, use_cuda):\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n    \n    model.eval()\n    for batch_idx, (data,target) in enumerate(test_loader):\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        with torch.no_grad():\n            model.requires_grad = False\n\n        output = model(data)\n        loss = criterion(output, target)\n        \n        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n        \n        output = F.softmax(output, dim=1)\n        pred = output.data.max(1, keepdim=True)[1]\n        \n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n        \n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))\n        \ntest(test_loader, VGG16, criterion, use_cuda)","execution_count":115,"outputs":[{"output_type":"stream","text":"Test Loss: 825233113088.000000\n\n\nTest Accuracy: 51% (689/1343)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}